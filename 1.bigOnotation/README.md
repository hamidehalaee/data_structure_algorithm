Big O is a way of describing the efficiency of algorithms without getting too mired in the details. It describes how the time (or the number of operations needed) it takes to run grows as the size of the input grows.

Big O notation helps us answer the question, "How do our functions or algorithms behave/scale when the size of the inputs increases significantly

Big O Notation is used in computer science to analyse the performance of an algorithm

Big O specifically looks at the worst-case scenario of an algorithm â€“ looking at the big picture. It tells us how long a function will take to execute (execution time) or how much space (e.g., in memory or disk) the function takes up as the input to that function approaches infinity (i.e. becomes very large)

sources:
1. https://dev.to/youssefzidan/understanding-big-o-notation-using-javascript-407o
2. https://dev.to/youssefzidan/understanding-big-o-notation-using-javascript-407o
